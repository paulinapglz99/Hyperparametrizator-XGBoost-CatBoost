{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b28bbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import cohen_kappa_score, mean_absolute_error, mean_squared_error, r2_score\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.optimize import minimize\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da1852b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define targets\n",
    "ordinal_targets = ['ADNC', 'Braak', 'Thal', 'CERAD']\n",
    "continuous_targets = ['percent 6e10 positive area', 'percent AT8 positive area', 'percent GFAP positive area', 'percent NeuN positive area']\n",
    "all_target_columns = ordinal_targets + continuous_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9fdc7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test model\n",
    "def test_model(df, target, region):\n",
    "    \n",
    "    ## Load trained model\n",
    "    model = joblib.load(f'./models/{region}/{region}_{target}_model.pkl')\n",
    "    \n",
    "    ## Prepare data (drop other targets and create feature matrix)\n",
    "    other_targets = [t for t in all_target_columns if t != target]\n",
    "    X = df.drop(columns=['Donor ID', target] + other_targets)\n",
    "    y = df[target].values\n",
    "    donor_ids = df['Donor ID'].values\n",
    "    \n",
    "    ## Make predictions (continuous values)\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    ## Calculate metrics based on target type (according to DREAM tasks)\n",
    "    \n",
    "    ## For ordinal targets\n",
    "    if target in ordinal_targets:\n",
    "        \n",
    "        ## Load optimized thresholds from trained model\n",
    "        optimized_thresholds = model.optimized_thresholds_\n",
    "        \n",
    "        ## Apply thresholds to get ordinal predictions\n",
    "        y_classes = np.digitize(y_pred, bins=optimized_thresholds)\n",
    "        \n",
    "        ## Calculate metrics for ordinal targets\n",
    "        metrics = {\n",
    "            'quadratic_weighted_kappa': cohen_kappa_score(y, y_classes, weights='quadratic'),\n",
    "            'mean_absolute_error': mean_absolute_error(y, y_classes),\n",
    "            'spearman_correlation': spearmanr(y, y_classes)[0],\n",
    "            'thresholds_used': str(optimized_thresholds.round(3))\n",
    "        }\n",
    "        \n",
    "        ## Calculate predictions for ordinal targets\n",
    "        predictions_df = pd.DataFrame({\n",
    "            'Donor ID': donor_ids,\n",
    "            'true_value': y,\n",
    "            'predicted_value': y_classes\n",
    "        })\n",
    "\n",
    "    else:\n",
    "        \n",
    "        ## Calculate metrics for continuous targets\n",
    "        mean_t, mean_p = np.mean(y), np.mean(y_pred)\n",
    "        var_t, var_p = np.var(y, ddof=1), np.var(y_pred, ddof=1)\n",
    "        ccc = (2 * np.cov(y, y_pred)[0,1]) / (var_t + var_p + (mean_t - mean_p)**2)\n",
    "        \n",
    "        metrics = {\n",
    "            'concordance_correlation_coefficient': ccc,\n",
    "            'mean_squared_error': mean_squared_error(y, y_pred),\n",
    "            'r2_score': r2_score(y, y_pred)\n",
    "        }\n",
    "        \n",
    "        ## Calculate predictions for continuous targets\n",
    "        predictions_df = pd.DataFrame({\n",
    "            'Donor ID': donor_ids,\n",
    "            'true_value': y,\n",
    "            'predicted_value': y_pred\n",
    "        })\n",
    "    \n",
    "    ## Save predictions\n",
    "    predictions_df.to_csv(f'./output/{region}/{region}_{target}_test_predictions.csv', index=False)\n",
    "    \n",
    "    ## Save metrics\n",
    "    metrics_df = pd.DataFrame(list(metrics.items()), columns=['metric_name', 'metric_value'])\n",
    "    metrics_df.to_csv(f'./output/{region}/{region}_{target}_test_metrics.csv', index=False)\n",
    "\n",
    "### Process all test datasets\n",
    "for csv_file in os.listdir('data/'):\n",
    "    if csv_file in ['dataset_mtg_ordered.csv', 'dataset_a9_ordered.csv']:\n",
    "        \n",
    "        region = 'MTG' if 'mtg' in csv_file else 'A9'\n",
    "        df = pd.read_csv(f'data/{csv_file}')\n",
    "        \n",
    "        for target in all_target_columns:\n",
    "            test_model(df, target, region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca2967c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process all test datasets\n",
    "for csv_file in os.listdir('data/'):\n",
    "    if csv_file in ['dataset_mtg_ordered.csv', 'dataset_a9_ordered.csv']:\n",
    "        \n",
    "        region = 'MTG' if 'mtg' in csv_file else 'A9'\n",
    "        df = pd.read_csv(f'data/{csv_file}')\n",
    "        \n",
    "        for target in all_target_columns:\n",
    "            test_model(df, target, region)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
