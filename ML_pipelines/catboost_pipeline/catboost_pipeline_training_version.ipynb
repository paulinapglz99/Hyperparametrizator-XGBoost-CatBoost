{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df28470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import cohen_kappa_score, mean_absolute_error, mean_squared_error, r2_score\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.optimize import minimize\n",
    "from functools import reduce\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8203b711",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define all types of targets\n",
    "\n",
    "ordinal_targets = ['ADNC', 'Braak', 'Thal', 'CERAD']\n",
    "continuous_targets = ['percent 6e10 positive area', 'percent AT8 positive area', \n",
    "                      'percent GFAP positive area', 'percent NeuN positive area']\n",
    "all_target_columns = ordinal_targets + continuous_targets\n",
    "\n",
    "### Categorical mappings for submission format\n",
    "MAPS = {\n",
    "    'ADNC': {0:\"Not AD\", 1:\"Low\", 2:\"Intermediate\", 3:\"High\"},\n",
    "    'Braak': {i:f\"Braak {['0','I','II','III','IV','V','VI'][i]}\" for i in range(7)},\n",
    "    'CERAD': {0:\"Absent\", 1:\"Sparse\", 2:\"Moderate\", 3:\"Frequent\"},\n",
    "    'Thal': {i:f\"Thal {i}\" for i in range(6)}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a7c87af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Reorder datasets\n",
    "\n",
    "# ### Read column order from CSV\n",
    "column_order = pd.read_csv('data/column_order.csv')['column_name'].tolist()\n",
    "\n",
    "### Load datasets\n",
    "df_mtg = pd.read_csv('data/dataset_mtg_dropped.csv')\n",
    "df_a9 = pd.read_csv('data/dataset_a9_dropped.csv')\n",
    "\n",
    "### Reorder datasets using the predefined column order\n",
    "df_mtg = df_mtg[column_order]\n",
    "df_a9 = df_a9[column_order]\n",
    "df_mtg.to_csv('data/dataset_mtg_ordered.csv', index=False)\n",
    "df_a9.to_csv('data/dataset_a9_ordered.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca148a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load hyperparameters\n",
    "\n",
    "def load_hyperparams():\n",
    "\n",
    "    ## Initialize dictionary to store hyperparameters by target and region\n",
    "    hyperparams = {}\n",
    "    ## Loop through each brain region\n",
    "    for region in ['MTG', 'A9']:\n",
    "        region_lower = region.lower()\n",
    "        ## Read and concatenate ordinal (QWK) and continuous (CCC) hyperparameters\n",
    "        df_hp = pd.concat([\n",
    "            pd.read_csv(f'hyperparam/CatBoost-hiperparametros_ordinales_optimizados_{region_lower}.csv'),\n",
    "            pd.read_csv(f'hyperparam/CatBoost-hiperparametros_continuos_optimizados_concordance_{region_lower}.csv')\n",
    "        ], ignore_index=True)\n",
    "        ## Convert to nested dictionary structure (target -> hyperparameters)\n",
    "        hyperparams[region] = df_hp.set_index('target').to_dict('index')\n",
    "    \n",
    "    return hyperparams\n",
    "\n",
    "hyperparams = load_hyperparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff3ef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Train models\n",
    "\n",
    "### Train final model\n",
    "def train_final_model(df, target, region, hyperparams_dict, random_state=42):\n",
    "\n",
    "    ## Prepare data (create feature matrix X without other targets and target vector y)\n",
    "    other_targets = [t for t in all_target_columns if t != target]\n",
    "    X = df.drop(columns=['Donor ID', target] + other_targets)\n",
    "    y = df[target].values\n",
    "    donor_ids = df['Donor ID'].values\n",
    "    \n",
    "    ## Get hyperparameters for this target and region\n",
    "    params = hyperparams_dict[region][target]\n",
    "    catboost_params = {k: v for k, v in params.items() \n",
    "                  if k not in ['best_qwk', 'best_ccc']}\n",
    "    \n",
    "    ## Choose eval_metric based on DREAM challenge task type\n",
    "    if target in ordinal_targets:\n",
    "        ## MAE correlates well with QWK for ordinal targets (Goal 1)\n",
    "        eval_metric = 'MAE'\n",
    "    else:\n",
    "        ## RMSE correlates well with CCC for continuous targets (Goal 2)\n",
    "        eval_metric = 'RMSE'\n",
    "    \n",
    "    ## Train model with target-specific hyperparameters and appropriate eval metric\n",
    "    model = CatBoostRegressor(\n",
    "        random_state=random_state,\n",
    "        eval_metric=eval_metric,\n",
    "        verbose=False,\n",
    "        **catboost_params\n",
    "    )\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    ## Calculate final metrics based on target type\n",
    "\n",
    "    ## For ordinal targets (ADNC, Braak, Thal, CERAD) - Goal 1\n",
    "    if target in ordinal_targets:\n",
    "\n",
    "        ## Optimize thresholds for converting continuous predictions to ordinal classes\n",
    "        class_props = pd.Series(y).value_counts(normalize=True).sort_index()\n",
    "        initial_th = np.quantile(y_pred, q=np.cumsum(class_props).iloc[:-1])\n",
    "        result = minimize(lambda th: -cohen_kappa_score(y, np.digitize(y_pred, bins=np.sort(th)), weights='quadratic'),\n",
    "                         x0=initial_th, method='Nelder-Mead')\n",
    "        \n",
    "        ## Store optimized thresholds as model attribute for use during testing\n",
    "        optimized_thresholds = np.sort(result.x)\n",
    "        model.optimized_thresholds_ = optimized_thresholds\n",
    "        \n",
    "        ## Apply thresholds to get ordinal class predictions\n",
    "        y_classes = np.digitize(y_pred, bins=optimized_thresholds)\n",
    "        \n",
    "        ## Calculate DREAM benchmark metrics for ordinal targets (QWK primary, MAE and Spearman secondary)\n",
    "        metrics = {\n",
    "            'quadratic_weighted_kappa': cohen_kappa_score(y, y_classes, weights='quadratic'),\n",
    "            'mean_absolute_error': mean_absolute_error(y, y_classes),\n",
    "            'spearman_correlation': spearmanr(y, y_classes)[0],\n",
    "            'optimized_thresholds': str(optimized_thresholds.round(3))\n",
    "        }\n",
    "        \n",
    "        ## Create predictions dataframe with ordinal classes\n",
    "        predictions_df = pd.DataFrame({'Donor ID': donor_ids, 'true_value': y, 'predicted_value': y_classes})\n",
    "\n",
    "    else:\n",
    "        ## For continuous targets (6e10, AT8, GFAP, NeuN) - Goal 2\n",
    "        \n",
    "        ## Calculate concordance correlation coefficient (CCC) - primary DREAM metric\n",
    "        mean_t, mean_p = np.mean(y), np.mean(y_pred)\n",
    "        var_t, var_p = np.var(y, ddof=1), np.var(y_pred, ddof=1)\n",
    "        ccc = (2 * np.cov(y, y_pred)[0,1]) / (var_t + var_p + (mean_t - mean_p)**2)\n",
    "        \n",
    "        ## Calculate DREAM benchmark metrics for continuous targets (CCC primary, MSE and R2 secondary)\n",
    "        metrics = {\n",
    "            'concordance_correlation_coefficient': ccc,\n",
    "            'mean_squared_error': mean_squared_error(y, y_pred),\n",
    "            'r2_score': r2_score(y, y_pred)\n",
    "        }\n",
    "        \n",
    "        ## Create predictions dataframe with continuous values\n",
    "        predictions_df = pd.DataFrame({'Donor ID': donor_ids, 'true_value': y, 'predicted_value': y_pred})\n",
    "\n",
    "        ## No thresholds needed for continuous targets\n",
    "        optimized_thresholds = None\n",
    "    \n",
    "    ## Save predictions to CSV\n",
    "    os.makedirs(f'./train_output/{region}', exist_ok=True)\n",
    "    predictions_df.to_csv(f'./train_output/{region}/{region}_{target}_train_predictions.csv', index=False)\n",
    "    \n",
    "    ## Save trained model with joblib\n",
    "    os.makedirs(f'./models/{region}', exist_ok=True)\n",
    "    joblib.dump({'model': model, 'thresholds': optimized_thresholds}, \n",
    "                f'./models/{region}/{region}_{target}_model.pkl')\n",
    "    \n",
    "    ## Save metrics to CSV\n",
    "    pd.DataFrame(list(metrics.items()), columns=['metric_name', 'metric_value']).to_csv(\n",
    "        f'./train_output/{region}/{region}_{target}_train_metrics.csv', index=False)\n",
    "    \n",
    "    ## Save feature importance ranking\n",
    "    feature_importance = model.get_feature_importance()\n",
    "    pd.DataFrame({'feature': X.columns, 'importance': feature_importance}).sort_values(\n",
    "        'importance', ascending=False).to_csv(f'./train_output/{region}/{region}_{target}_train_feature_importance.csv', index=False)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "### Process all targets per region with their respective target-specific hyperparameters\n",
    "datasets = {'MTG': df_mtg, 'A9': df_a9}\n",
    "train_metrics = {region: {target: train_final_model(df, target, region, hyperparams) \n",
    "                          for target in all_target_columns} for region, df in datasets.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ee9606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Format train submissions\n",
    "\n",
    "def format_evaluation(f, mode='train'):\n",
    "\n",
    "    ## Extract target name from filename (format: {region}_{target}_train_predictions.csv)\n",
    "    parts = f.split('/')[-1].replace(f'_{mode}_predictions.csv', '').split('_')\n",
    "    target = '_'.join(parts[1:])\n",
    "    \n",
    "    ## Load test predictions and ensure data type (string) in Donor ID\n",
    "    df = pd.read_csv(f)[['Donor ID', 'predicted_value']]\n",
    "    df['Donor ID'] = df['Donor ID'].astype(str)\n",
    "    \n",
    "    ## Convert predictions: categorical to strings, continuous to clipped float [0,100]\n",
    "    if target in MAPS:\n",
    "        df['predicted_value'] = df['predicted_value'].round().astype(int).map(MAPS[target])\n",
    "    else:\n",
    "        df['predicted_value'] = df['predicted_value'].clip(0, 100).astype(float)\n",
    "    \n",
    "    ## Format column name for submission\n",
    "    col_name = f\"predicted {target.replace('percent ','').replace(' positive area','')}\"\n",
    "    return df.rename(columns={'predicted_value': col_name})\n",
    "\n",
    "### Process all predictions per target and region\n",
    "for region in ['MTG', 'A9']:\n",
    "    files = [f'./train_output/{region}/{region}_{t}_train_predictions.csv' for t in all_target_columns]\n",
    "    reduce(lambda l,r: l.merge(r, on='Donor ID'), map(lambda f: format_evaluation(f, 'train'), files)).to_csv(\n",
    "        f'./train_output/{region}/submission_{region}_train.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291b6941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Test models\n",
    "\n",
    "def test_model(df, target, region):\n",
    "    \n",
    "    ## Load model and thresholds from single file\n",
    "    saved = joblib.load(f'./models/{region}/{region}_{target}_model.pkl')\n",
    "    model, thresholds = saved['model'], saved['thresholds']\n",
    "    \n",
    "    ## Prepare test data (drop other targets and create feature matrix)\n",
    "    other_targets = [t for t in all_target_columns if t != target]\n",
    "    X = df.drop(columns=['Donor ID', target] + other_targets)\n",
    "    y = df[target].values\n",
    "    donor_ids = df['Donor ID'].values\n",
    "    \n",
    "    ## Make predictions (continuous values from CatBoost regressor)\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    ## Calculate final DREAM challenge metrics based on target type\n",
    "    \n",
    "    ## For ordinal targets (ADNC, Braak, Thal, CERAD) - Goal 1\n",
    "    if target in ordinal_targets:\n",
    "        \n",
    "        ## Apply thresholds to convert continuous predictions to ordinal classes\n",
    "        y_classes = np.digitize(y_pred, bins=thresholds)\n",
    "        \n",
    "        ## Calculate DREAM benchmark metrics for ordinal targets (QWK primary, MAE and Spearman secondary)\n",
    "        metrics = {\n",
    "            'quadratic_weighted_kappa': cohen_kappa_score(y, y_classes, weights='quadratic'),\n",
    "            'mean_absolute_error': mean_absolute_error(y, y_classes),\n",
    "            'spearman_correlation': spearmanr(y, y_classes)[0],\n",
    "            'thresholds_used': str(thresholds.round(3))\n",
    "        }\n",
    "        \n",
    "        ## Create predictions dataframe with ordinal classes\n",
    "        predictions_df = pd.DataFrame({'Donor ID': donor_ids, 'true_value': y, 'predicted_value': y_classes})\n",
    "    \n",
    "    else:\n",
    "        ## For continuous targets (6e10, AT8, GFAP, NeuN) - Goal 2\n",
    "        \n",
    "        ## Calculate concordance correlation coefficient (CCC) - primary DREAM metric\n",
    "        mean_t, mean_p = np.mean(y), np.mean(y_pred)\n",
    "        var_t, var_p = np.var(y, ddof=1), np.var(y_pred, ddof=1)\n",
    "        ccc = (2 * np.cov(y, y_pred)[0,1]) / (var_t + var_p + (mean_t - mean_p)**2)\n",
    "        \n",
    "        ## Calculate DREAM benchmark metrics for continuous targets (CCC primary, MSE and R2 secondary)\n",
    "        metrics = {\n",
    "            'concordance_correlation_coefficient': ccc,\n",
    "            'mean_squared_error': mean_squared_error(y, y_pred),\n",
    "            'r2_score': r2_score(y, y_pred)\n",
    "        }\n",
    "        \n",
    "        ## Create predictions dataframe with continuous values\n",
    "        predictions_df = pd.DataFrame({'Donor ID': donor_ids, 'true_value': y, 'predicted_value': y_pred})\n",
    "    \n",
    "    ## Save test predictions to CSV\n",
    "    os.makedirs(f'./test_output/{region}', exist_ok=True)\n",
    "    predictions_df.to_csv(f'./test_output/{region}/{region}_{target}_test_predictions.csv', index=False)\n",
    "    \n",
    "    ## Save test metrics to CSV\n",
    "    pd.DataFrame(list(metrics.items()), columns=['metric_name', 'metric_value']).to_csv(\n",
    "        f'./test_output/{region}/{region}_{target}_test_metrics.csv', index=False)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "### Process all test datasets with their respective trained models\n",
    "test_metrics = {region: {target: test_model(df, target, region) \n",
    "                         for target in all_target_columns} for region, df in datasets.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea549cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Format test submissions\n",
    "\n",
    "### Process all predictions per target and region\n",
    "for region in ['MTG', 'A9']:\n",
    "    files = [f'./test_output/{region}/{region}_{t}_test_predictions.csv' for t in all_target_columns]\n",
    "    reduce(lambda l,r: l.merge(r, on='Donor ID'), map(lambda f: format_evaluation(f, 'test'), files)).to_csv(\n",
    "        f'./test_output/{region}/submission_{region}_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8c1969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Compare models between regions\n",
    "\n",
    "def compare_target(target):\n",
    "    \n",
    "    ## Determine primary metric based on target type\n",
    "    metric_name = 'quadratic_weighted_kappa' if target in ordinal_targets else 'concordance_correlation_coefficient'\n",
    "    ## Extract metrics from both regions\n",
    "    mtg_metric = test_metrics['MTG'][target][metric_name]\n",
    "    a9_metric = test_metrics['A9'][target][metric_name]\n",
    "    \n",
    "    return {\n",
    "        'Target': target,\n",
    "        'Metric': 'QWK' if target in ordinal_targets else 'CCC',\n",
    "        'MTG_Score': mtg_metric,\n",
    "        'A9_Score': a9_metric,\n",
    "        'Best_Region': 'MTG' if mtg_metric > a9_metric else 'A9',\n",
    "        'Best_Score': max(mtg_metric, a9_metric),\n",
    "        'Difference': abs(mtg_metric - a9_metric)\n",
    "    }\n",
    "\n",
    "pd.DataFrame([compare_target(t) for t in all_target_columns]).to_csv('./test_output/model_comparison_A9_vs_MTG.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
